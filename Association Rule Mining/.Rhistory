gbm_cfm[2,3] <- length(which(evaluation[,1] == 2 & evaluation[,2] == 3))
gbm_cfm[3,1] <- length(which(evaluation[,1] == 3 & evaluation[,2] == 1))
gbm_cfm[3,2] <- length(which(evaluation[,1] == 3 & evaluation[,2] == 2))
gbm_cfm[3,3] <- length(which(evaluation[,1] == 3 & evaluation[,2] == 3))
gbm_perf[iter_cnt,1] <- gbmGrid$n.trees[i]
gbm_perf[iter_cnt,2] <- gbmGrid$shrinkage[i]
gbm_perf[iter_cnt,3:4] <- t(perf_eval_multi(gbm_cfm))
iter_cnt = iter_cnt +1
}
end.time9 <- proc.time()
time9 <- end.time9 - start.time9
time9
gbm_perf <- gbm_perf[order(gbm_perf[,4],decreasing = TRUE),]
colnames(gbm_perf) <- c("n.trees","shrinkage","ACC","BCR")
gbm_perf
best_tree <- gbm_perf[1,1]
best_shrinkage <- gbm_perf[1,2]
gbm.model <- gbm.fit(data[,input_idx],data[,target_idx], distribution = "multinomial",verbose = TRUE, n.trees = best_tree, shrinkage = best_shrinkage)
summary <- summary(gbm.model)
gbm.pred <- as.data.frame(predict(gbm.model, GBM.tst[,input_idx], type = "response", n.trees = best_tree))
gbm.cfm <- table(max.col(gbm.pred), GBM.tst$GradeYN)
gbm.cfm
perf_table[8,] <- perf_eval_multi(gbm.cfm)
perf_table
p
p
gbm_perf <- gbm_perf[order(gbm_perf[,4],decreasing = TRUE),]
colnames(gbm_perf) <- c("n.trees","shrinkage","ACC","BCR")
gbm_perf
summary <- summary(gbm.model)
summary
summary(gbm.model)
gbm.pred <- as.data.frame(predict(gbm.model, GBM.tst[,input_idx], type = "response", n.trees = best_tree))
gbm.cfm <- table(max.col(gbm.pred), GBM.tst$GradeYN)
gbm.cfm
perf_table
#Question 8: Performance Evaluation of All Constructed models
perf_table
perf_table_test <- perf_table
perf_table_test
perf_table_test <- ann_bagging_othercomp[6,]
ann_bagging_othercomp <- c(0.657214, 0.4521863)
perf_table_test <- ann_bagging_othercomp[6,]
ann_bagging_othercomp
perf_table_test <- ann_bagging_othercomp[,6]
perf_table_test <- ann_bagging_othercomp[]
perf_table_test
#Question 8: Performance Evaluation of All Constructed models
perf_table_test <- perf_table
perf_table_test
perf_table_test <- ann_bagging_othercomp[6,1:2]
#Question 8: Performance Evaluation of All Constructed models
perf_table_test <- perf_table
perf_table_test
ann_bagging_othercomp <- c(0.657214, 0.4521863)
perf_table_test <- peft_table_test(ann_bagging_othercomp[6,1:2])
ann_bagging_othercomp <- c(0.657214, 0.4521863)
perf_table_test <- perf_table_test(ann_bagging_othercomp[6,1:2])
#Question 8: Performance Evaluation of All Constructed models
perf_table_test <- perf_table
perf_table_test
ann_bagging_othercomp <- c(0.657214, 0.4521863)
perf_table_test <- perf_table_test(ann_bagging_othercomp[6,1:2])
perf_table_test <- ann_bagging_othercomp(c[6,1:2])
ann_bagging_othercomp <- c(0.657214, 0.4521863)
perf_table_test <- ann_bagging_othercomp(c[6,1:2])
perf_table_test[6,] <- ann_bagging_othercomp
perf_table_test
#Question 8: Performance Evaluation of All Constructed models
perf_table_test <- perf_table
perf_table_test
ann_bagging_othercomp <- c(0.657214, 0.4521863)
perf_table_test[6,] <- ann_bagging_othercomp
perf_table_test
perf_table <- perf_table_test
perf_table
perf_table_final <- perf_table[order(perf_table[,2],decreasing = TRUE),]
perf_table_final
time9
#Training Time Table
time_table <- matrix(0, nrow = 8, ncol = 1)
colnames(time_table) <- c("Elapsed Time")
rownames(time_table) <- c("MLR","CART","ANN","Bagging CART",
"Random Forests","Bagging ANN","AdaBoost","GBM")
time_table
#training time comparison
time_table <- matrix(0, nrow = 8, ncol = 1)
colnames(time_table) <- c("Elapsed Time")
rownames(time_table) <- c("MLR","CART","ANN","Bagging CART",
"Random Forests","Bagging ANN","AdaBoost","GBM")
time_table
time_table[1,] <- time1
time_table
time1
time_table[1,] <- time1[,3]
time_table[1,] <- time1[1,3]
time_table[1,] <- time1[2,3]
time_table[1,] <- time1(c[2,3])
time_table[1,] <- time1[2,3]
time_table[1,] <- time1(2,3)
time_table[1,] <- time1[2,3]
time_table
time_table[1,2] <- time1[2,3]
time_table[1,2] <- time1[1,3]
time_table[1,2] <- time1[3]
time_table
time_table[1,] <- time1[3]
time_table
time_table[1,] <- time1[3]
time_table[2,] <- time2[3]
time_table[3,] <- time3[3]
time_table[4,] <- time4[3]
time_table[5,] <- time5[3]
time_table[6,] <- time6[3]
time_table[7,] <- time7[3]
#training time comparison
time_table <- matrix(0, nrow = 9, ncol = 1)
colnames(time_table) <- c("Elapsed Time")
rownames(time_table) <- c("MLR","CART","ANN","Bagging CART",
"Random Forests","ANN with iterations","Bagging ANN","AdaBoost","GBM")
time_table
time_table[1,] <- time1[3]
time_table[2,] <- time2[3]
time_table[3,] <- time3[3]
time_table[4,] <- time4[3]
time_table[5,] <- time5[3]
time_table[6,] <- time6[3]
time_table[7,] <- time7[3]
time_table[8,] <- time8[3]
time_table[9,] <- time9[3]
time_table
time_table_final <- time_table[order(time_table[,1],decreasing = TRUE)]
time_table_final
time_table_final <- time_table[order(time_table[,2],decreasing = TRUE)]
time_table_final
time_table
time_table_final <- time_table[order(time_table[,1],decreasing = TRUE),]
time_table_final
time_table_final <- time_table[order(time_table[1,],decreasing = TRUE),]
time_table_final
time_table_final <- time_table[order(time_table[,2],decreasing = TRUE),]
time_table_final <- time_table[order(time_table[,1],decreasing = TRUE),]
time_table_final
perf_table
perf_table_final <- perf_table[order(perf_table[,2],decreasing = TRUE),]
perf_table_final
time_table_final <- time_table[order(time_table[],decreasing = TRUE),]
time_table_final
time_table_final <- time_table[order(time_table[,],decreasing = TRUE),]
time_table_final
time_table_final
View(time_table)
time_table_final <- time_table[order(time_table[,1],decreasing = TRUE),]
time_table_final
time_table_final <- time_table[order(time_table[,1],decreasing = TRUE),]
time_table_final
time_table_final <- time_table[order(time_table[1],decreasing = TRUE),]
time_table_final
time_table_final <- matrix(time_table[order(time_table[,1],decreasing = TRUE),])
time_table_final
time_table_final <- matrix(time_table[order(time_table[,1],decreasing = TRUE),])
colnames(time_table_final) <- c("Elapsed Time")
rownames(time_table_final) <- c("MLR","CART","ANN","Bagging CART",
"Random Forests","ANN with iterations","Bagging ANN","AdaBoost","GBM")
time_table_final
time_table_final <- matrix(time_table[order(time_table[,1],decreasing = TRUE),])
colnames(time_table_final) <- c("Elapsed Time")
rownames(time_table_final) <- c("Bagging CART","ANN with iterations","ANN","Random Forests",
"AdaBoost","GBM","CART","MLR","Bagging ANN")
time_table_final
#training time comparison
time_table <- matrix(0, nrow = 9, ncol = 1)
colnames(time_table) <- c("Elapsed Time")
rownames(time_table) <- c("MLR","CART","ANN","Bagging CART",
"Random Forests","ANN with iterations","Bagging ANN","AdaBoost","GBM")
time_table
time_table[1,] <- time1[3]
time_table[2,] <- time2[3]
time_table[3,] <- time3[3]
time_table[4,] <- time4[3]
time_table[5,] <- time5[3]
time_table[6,] <- time6[3]
time_table[7,] <- time7[3]
time_table[8,] <- time8[3]
time_table[9,] <- time9[3]
time_table
time_table_final <- matrix(time_table[order(time_table[,1],decreasing = TRUE),])
colnames(time_table_final) <- c("Elapsed Time")
rownames(time_table_final) <- c("Bagging CART","ANN with iterations","ANN","Random Forests",
"AdaBoost","GBM","CART","MLR","Bagging ANN")
time_table_final
time_table_final <- time_table[order(time_table[,1],decreasing = TRUE),]
time_table_final
#training time comparison
time_table <- matrix(0, nrow = 9, ncol = 1)
colnames(time_table) <- c("Elapsed Time")
rownames(time_table) <- c("MLR","CART","ANN","Bagging CART",
"Random Forests","ANN with iterations","Bagging ANN","AdaBoost","GBM")
time_table
time_table[1,] <- time1[3]
time_table[2,] <- time2[3]
time_table[3,] <- time3[3]
time_table[4,] <- time4[3]
time_table[5,] <- time5[3]
time_table[6,] <- time6[3]
time_table[7,] <- time7[3]
time_table[8,] <- time8[3]
time_table[9,] <- time9[3]
time_table
time_table_final <- time_table[order(time_table[,1],decreasing = TRUE),]
time_table_final
time_table_final
save.image("~/Desktop/beforeextra.RData")
#Extra Question - Regularization
set.seed(12345)
trn_smote <- damage_smote[sample(nrow(damage_smote),4385),]
val_smote <- damage_smote[sample(nrow(damage_smote),1512),]
#Upsampling
Damage_up <- upSample(subset(Final_data, select = -Class),Final_data$Class)
table(Damage_up$Class)
#Extra Question - Regularization by upsampling
Damage_up <- upSample(subset(Final_data, select = -Class),Final_data$Class)
table(Damage_up$Class)
RF.ensem <- randomForest(GradeYN ~., data = CART_trn_up, ntree = 300, mincriterion = best_criterion, min_split = best_split, maxdepth = max_depth, importance = TRUE, do.trace = TRUE)
Damage_up
best_criterion
set.seed(12345)
trn_up <- Damage_up[sample(nrow(Damage_up),15044),]
val_up <- Damage_up[sample(nrow(Damage_up),5013),]
tst_up <- Damage_up[sample(nrow(Damage_up),6016),]
#Extra Question - Regularization by upsampling
Damage_up <- upSample(subset(Final_data, select = -Class),Final_data$Class)
table(Damage_up$Class)
set.seed(12345)
trn_up <- Damage_up[sample(nrow(Damage_up),15044),]
val_up <- Damage_up[sample(nrow(Damage_up),5013),]
tst_up <- Damage_up[sample(nrow(Damage_up),6016),]
input_idx <- c(1:68)
target_idx <- 69
CART_trn_up <- data.frame(trn_up[,input_idx], GradeYN = trn_up[,target_idx])
CART_val_up <- data.frame(val_up[,input_idx], GradeYN = val_up[,target_idx])
CART_tst_up <- data.frame(tst_up[,input_idx], GradeYN = tst_up[,target_idx])
RF.ensem <- randomForest(GradeYN ~., data = CART_trn_up, ntree = 300,
mincriterion = best_criterion, min_split = best_split,
maxdepth = max_depth, importance = TRUE, do.trace = TRUE)
RF.ensem.pred <- predict(RF.ensem, newdata = CART_tst_up, type = "class")
RF.ensem.cfm <- table(CART_tst_up$GradeYN,RF.ensem.pred)
RF.ensem.cfm
perf.table.extra[1,] <- perf_eval_multi(RF.ensem.cfm)
perf_eval_multi(RF.ensem.cfm)
print(RF.ensem)
plot(RF.ensem)
Var.imp.up <- importance(RF.ensem)
summary(Var.imp.up)
barplot(Var.imp.up[order(Var.imp.up[,4],decreasing = TRUE),4])
RF.ensem.cfm
perf_eval_multi(RF.ensem.cfm)
save.image("~/a6finaldata.RData")
library(arules)
library(arulesViz)
library(wordcloud)
setwd("~/Desktop/Assignment_7_Jonghyunlee_2015170867")
#Step1: Data Preparation
mooc_dataset <- read.csv("big_student_clear_third_version.csv")
View(mooc_dataset)
Institute <- mooc_dataset[,c(2)]
Course <- mooc_dataset[,c(3)]
Region <- gsub(" ","",mooc_dataset[,c(10)])
Degree <- gsub(" ","",mooc_dataset[,c(11)])
Transaction_ID <- mooc_dataset[,c(6)]
RawTransactions <- paste(Institute, Course, Region, Degree, sep = '_')
MOOC_transactions <- paste(Transaction_ID, RawTransactions, sep = ' ')
write.csv(MOOC_transactions, file = "MOOC_User_Course.csv", row.names = FALSE, quote = FALSE)
#Step2: Read Data
#Question 2-1
MOOC_single <- read.transactions("MOOC_User_Course.csv", format = "single",
header = TRUE, cols = c(1,2),
rm.duplicates = TRUE, skip = 1)
install.packages("psych")
library(psych)
inspect(MOOC_single)
describe(MOOC_single)
str(MOOC_single)
#Question 2-2
itemName <- itemLabels(MOOC_single)
itemCount <- itemFrequency(MOOC_single)*nrow(MOOC_single)
col <- brewer.pal(8,"Paired")
wordcloud(words = itemName, freq = itemCount, min.freq = 1000,
scale = c(1,0.2), col = col, rot.per = 0.2, random.order = FALSE)
#Question 2-3
itemFrequencyPlot(MOOC_single, support = 0.01, cex.names = 0.8)
itemFrequencyPlot(MOOC_single, topN = 5, type = "absolute", cex.names = 0.8)
#Step3: Generate Rules and Interpret Results
#Question 3-1
support_rule <- c(0.0005, 0.0015, 0.002, 0.0025)
confidence_rule <- c(0.005, 0.01, 0.1)
matrix_rules <- matrix(0,4,3)
rownames(matrix_rules) <- paste0("Support = ",support_rule)
colnames(matrix_rules) <- paste0("Confidence = ",confidence_rule)
matrix_rules
start.time <- proc.time()
for(i in 1:4){
for(j in 1:3){
tmp_a <- support_rule[i]
tmp_b <- confidence_rule[j]
cat("Support:",support_rule[i],",Confidence:",confidence_rule[j],"\n")
rules_tmp <- apriori(MOOC_single, parameter = list(support = tmp_a, confidence = tmp_b))
rules_tmp <- data.frame(length(rules_tmp), tmp_a, tmp_b)
tmp_cnt <- rules_tmp[,1]
matrix_rules[i,j] <- tmp_cnt
}
}
end.time <- proc.time()
time <- end.time - start.time
time
write.csv(matrix_rules, file = "question_3_1.csv")
#Question 3-2
rules_as <- apriori(MOOC_single, parameter = list(support = 0.001, confidence = 0.05))
inspect(rules_as)
inspect(sort(rules_as, by = "support"))
inspect(sort(rules_as, by = "confidence"))
inspect(sort(rules_as, by = "lift"))
rules_as
str(rules_as)
rules_as_df <- DATAFRAME(rules_as)
rules_as_df$Perf_Mea_New <- rules_as_df$support * rules_as_df$confidence * rules_as_df$lift
rules_as_df <- rules_as_df[order(rules_as_df[,7],decreasing = T),]
rules_as_df
write.csv(rules_as_df, file = "rules_perf_new.csv", row.names = FALSE)
boxplot(rules_as_df$lift, main = "lift")
points(mean(rules_as_df$lift))
summary(boxplot(rules_as_df$support))
plot(rules_as, method = "graph")
rules_1 <- subset(rules_as, lhs %pin% c("MITx_6.002x_India_Secondary"))
inspect(rules_1)
inspect(MOOC_single)
inspect(MOOC_single)
summary(MOOC_single)
View(MOOC_single)
#Question 2-2 Wordcloud
itemName <- itemLabels(MOOC_single)
itemCount <- itemFrequency(MOOC_single)*nrow(MOOC_single)
col <- brewer.pal(8,"Paired")
wordcloud(words = itemName, freq = itemCount, min.freq = 1000,
scale = c(1,0.2), col = col, rot.per = 0.2, random.order = FALSE)
col <- brewer.pal(9,"Pastel1")
#Question 2-2 Wordcloud
itemName <- itemLabels(MOOC_single)
itemCount <- itemFrequency(MOOC_single)*nrow(MOOC_single)
col <- brewer.pal(9,"Pastel1")
wordcloud(words = itemName, freq = itemCount, min.freq = 1000,
scale = c(1,0.2), col = col, rot.per = 0.2, random.order = FALSE)
col <- brewer.pal(8,"Dark2")
wordcloud(words = itemName, freq = itemCount, min.freq = 1000,
scale = c(1,0.2), col = col, rot.per = 0.2, random.order = FALSE)
#Question 2-2 Wordcloud
itemName <- itemLabels(MOOC_single)
itemCount <- itemFrequency(MOOC_single)*nrow(MOOC_single)
col <- brewer.pal(8,"Dark2")
wordcloud(words = itemName, freq = itemCount, min.freq = 1000,
scale = c(1,0.2), col = col, rot.per = 0.2, random.order = FALSE)
wordcloud(words = itemName, freq = itemCount, min.freq = 1000,
scale = c(1,0.2), col = brewer.pal(8,"Dark2"), rot.per = 0.2, random.order = FALSE)
wordcloud(words = itemName, freq = itemCount, min.freq = 1000,
scale = c(3,0.2), col = brewer.pal(8,"Dark2"), rot.per = 0.2, random.order = FALSE)
wordcloud(words = itemName, freq = itemCount, min.freq = 1000,
scale = c(2,0.2), col = brewer.pal(8,"Dark2"), rot.per = 0.2, random.order = FALSE)
wordcloud(words = itemName, freq = itemCount, min.freq = 1000,
scale = c(1.5,0.2), col = brewer.pal(8,"Dark2"), rot.per = 0.2, random.order = FALSE)
wordcloud(words = itemName, freq = itemCount, min.freq = 1000,
scale = c(1.2,0.2), col = brewer.pal(8,"Dark2"), rot.per = 0.2, random.order = FALSE)
wordcloud(words = itemName, freq = itemCount, min.freq = 1000,
scale = c(1.2,0.2), col = brewer.pal(8,"Dark2"), random.order = FALSE)
wordcloud(words = itemName, freq = itemCount, min.freq = 2000,
scale = c(1.2,0.2), col = brewer.pal(8,"Dark2"), random.order = FALSE)
wordcloud(words = itemName, freq = itemCount, min.freq = 700,
scale = c(1.2,0.2), col = brewer.pal(8,"Dark2"), random.order = FALSE)
#Question 2-3
itemFrequencyPlot(MOOC_single, support = 0.01, cex.names = 0.8)
itemFrequencyPlot(MOOC_single, topN = 5, type = "absolute", cex.names = 0.8)
#Question 2-3 Bar chart
itemFrequencyPlot(MOOC_single, support = 0.01, cex.names = 0.8)
itemFrequencyPlot(MOOC_single, topN = 5, type = "absolute", cex.names = 0.8)
#Question 2-3 Bar chart
itemFrequencyPlot(MOOC_single, support = 0.01, cex.names = 0.8)
itemFrequencyPlot(MOOC_single, topN = 5, type = "absolute", cex.names = 0.8)
matrix_rules
fixed_h <- apriori(MOOC_single, parameter = list(support = 0.001, confidence = 0.05))
inspect(fixed_h)
inspect(sort(fixed_h, by = "support"))
inspect(sort(fixed_h, by = "confidence"))
inspect(sort(fixed_h, by = "lift"))
fixed_h
str(fixed_h)
fixed_h_df <- DATAFRAME(fixed_h)
fixed_h_df$Perf_Mea_New <- fixed_h_df$support * fixed_h_df$confidence * fixed_h_df$lift
fixed_h_df <- fixed_h_df[order(fixed_h_df[,7],decreasing = T),]
fixed_h_df
write.csv(fixed_h_df, file = "rules_perf_new.csv", row.names = FALSE)
boxplot(fixed_h_df$lift, main = "lift")
points(mean(fixed_h_df$lift))
summary(boxplot(fixed_h_df$support))
plot(fixed_h, method = "graph")
rules_1 <- subset(fixed_h, lhs %pin% c("MITx_6.002x_India_Secondary"))
inspect(rules_1)
#Question 3-2: fixed hyperparameters
fixed_h <- apriori(MOOC_single, parameter = list(support = 0.001, confidence = 0.05))
inspect(fixed_h)
inspect(sort(fixed_h, by = "support"))
inspect(sort(fixed_h, by = "confidence"))
inspect(sort(fixed_h, by = "lift"))
fixed_h
str(fixed_h)
fixed_h
inspect(fixed_h)
inspect(sort(fixed_h, by = "support"))
inspect(sort(fixed_h, by = "support"))
inspect(sort(fixed_h, by = "confidence"))
inspect(sort(fixed_h, by = "lift"))
inspect(sort(fixed_h, by = "confidence"))
inspect(sort(fixed_h, by = "lift"))
fixed_h_df <- DATAFRAME(fixed_h)
#support x confidence x lift
fixed_h_df <- DATAFRAME(fixed_h)
fixed_h_df$Perf_Mea_New <- fixed_h_df$support * fixed_h_df$confidence * fixed_h_df$lift
fixed_h_df <- fixed_h_df[order(fixed_h_df[,7],decreasing = T),]
fixed_h_df
fixed_h_df$Perf_New <- fixed_h_df$support * fixed_h_df$confidence * fixed_h_df$lift
fixed_h_df <- fixed_h_df[order(fixed_h_df[,7],decreasing = T),]
fixed_h_df
#support x confidence x lift
fixed_h_df <- DATAFRAME(fixed_h)
fixed_h_df$Perf_New <- fixed_h_df$support * fixed_h_df$confidence * fixed_h_df$lift
fixed_h_df <- fixed_h_df[order(fixed_h_df[,7],decreasing = T),]
fixed_h_df
#support x confidence x lift
fixed_h_df <- DATAFRAME(fixed_h)
fixed_h_df$Perf_New <- fixed_h_df$support * fixed_h_df$confidence * fixed_h_df$lift
fixed_h_df <- fixed_h_df[order(fixed_h_df[,8],decreasing = T),]
fixed_h_df
boxplot(fixed_h_df$lift, main = "lift")
points(mean(fixed_h_df$lift))
summary(boxplot(fixed_h_df$support))
plot(fixed_h, method = "graph")
plot(fixed_h, method = "graph")
rules_1 <- subset(fixed_h, lhs %pin% c("MITx_6.002x_India_Secondary"))
inspect(rules_1)
rules
rules <- subset(fixed_h, lhs %pin% c("MITx_6.002x_India_Secondary"))
inspect(rules)
plot(fixed_h, method = "graph")
rules <- subset(fixed_h, lhs %pin% c("MITx_6.002x_India_Secondary"))
inspect(rules)
rules1 <- subset(fixed_h, lhs %pin% c("MITx_8.02x_India_Secondary"))
inspect(rules1)
rules2 <- subset(fixed_h, lhs %pin% c("HarvardX_CS50x_India_Secondary"))
inspect(rules2)
rules <- subset(fixed_h, lhs %pin% c("HarvardX_CS50x_UnitedStates)Master's"))
inspect(rules)
plot(fixed_h, method = "graph")
rules <- subset(fixed_h, lhs %pin% c("HarvardX_CS50x_UnitedStates)Master's"))
inspect(rules)
plot(fixed_h, method = "graph")
rules <- subset(fixed_h, lhs %pin% c("HarvardX_CS50x_UnitedStates_Master's"))
inspect(rules)
rules1 <- subset(fixed_h, lhs %pin% c("MITx_6.00x_UnitedStates_Master's"))
inspect(rules1)
rules2 <- subset(fixed_h, lhs %pin% c("MITx_6.00x_UnitedStates_Secondary"))
inspect(rules2)
rules3 <- subset(fixed_h, lhs %pin% c("MITx_6.002x_UnitedStates_Secondary"))
inspect(rules3)
rules4 <- subset(fixed_h, lhs %pin% c("MITx_6.002x_India_Bachelor's"))
inspect(rules4)
rules5 <- subset(fixed_h, lhs %pin% c("MITx_6.00x_India_Bachelor's"))
inspect(rules5)
rules <- subset(fixed_h, lhs %pin% c("HarvardX_CS50x_UnitedStates_Master's"))
inspect(rules)
rules1 <- subset(fixed_h, lhs %pin% c("MITx_6.00x_UnitedStates_Master's"))
inspect(rules1)
rules2 <- subset(fixed_h, lhs %pin% c("MITx_6.00x_UnitedStates_Secondary"))
inspect(rules2)
rules3 <- subset(fixed_h, lhs %pin% c("MITx_6.002x_UnitedStates_Secondary"))
inspect(rules3)
rules4 <- subset(fixed_h, lhs %pin% c("MITx_6.002x_India_Bachelor's"))
inspect(rules4)
rules5 <- subset(fixed_h, lhs %pin% c("MITx_6.00x_India_Bachelor's"))
inspect(rules5)
inspect(rules)
inspect(rules1)
inspect(rules2)
inspect(rules3)
inspect(rules4)
inspect(rules5)
#Extra Question
#Grouped matrix for association rules
plot(fixed_h, method = "grouped")
plot(fixed_h, method = "graph", interactive = T)
plot(fixed_h, method = "graph", engine = 'interactive')
plot(fixed_h, method = "matrix", engine = "3d", measure = "lift")
plot(fided_h, measure = c("support", "lift"), shading = "confidence")
plot(fixed_h, measure = c("support", "lift"), shading = "confidence")
plot(fixed_h, measure = c("support", "lift"), shading = "confidence", jitter = 0)
plot(rules, method = "two-key plot")
plot(fixed_h, method = "two-key plot")
#Extra Question
#Grouped matrix for association rules
plot(fixed_h, method = "grouped")
plot(fixed_h, method = "paracoord")
#Extra Question
plot(fixed_h, method = "grouped")
plot(fixed_h, method = "matrix", engine = "3d", measure = "lift")
plot(fixed_h, measure = c("support", "lift"), shading = "confidence", jitter = 0)
