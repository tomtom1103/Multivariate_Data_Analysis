#Prediction
CART_prey2 <- predict(CART_diabetes, CART_tst2, type = "class")
CART_cm_diabetes <- table(CART_tst2$diabetesYN, CART_prey2)
CART_cm_diabetes
#Performance Evaluation
Perf_Table2[1,1:6] <- perf_eval(CART_cm_diabetes)
Perf_Table2
diabetes_CART_response <- predict(CART_diabetes, newdata = CART_tst2, type = 'vector')
diabetes_CART_response <- diabetes_CART_response[,1]
diabetes_CART_prob <- 1-unlist(diabetes_CART_response, use.names = F)[seq(1,nrow(CART_tst2),1)]
diabetes_CART_prob
diabetes_CART_rocr <- prediction(diabetes_CART_prob, CART_tst2$diabetesYN)
diabetes_CART_perf <- performance(diabetes_CART_rocr, "tpr", "fpr")
plot(diabetes_CART_perf, col = 5, lwd = 3)
Perf_Table2[1,7] <- unlist(performance(diabetes_CART_rocr, "auc")@y.values)
Perf_Table2
#question 3-1
#Post_Pruning
set.seed(12345)
CART_post_diabetes <- cv.tree(CART_diabetes, FUN = prune.misclass)
plot(CART_post_diabetes$size, CART_post_diabetes$dev, type = "b")
CART_post_diabetes
#Set best size which has minimum dev.
CART_post_pruned_diabetes <- prune.misclass(CART_diabetes, best = 4)
summary(CART_post_pruned_diabetes)
plot(CART_post_pruned_diabetes)
text(CART_post_pruned_diabetes, pretty = 1)
CART_post_prey_diabetes <- predict(CART_post_pruned_diabetes,CART_tst2, type = "class")
CART_post_cm_diabetes <- table(CART_tst2$diabetesYN, CART_post_prey_diabetes)
CART_post_cm_diabetes
Perf_Table2[2,1:6] <- perf_eval(CART_post_cm_diabetes)
Perf_Table2
diabetes_post_response <- predict(CART_post_pruned_diabetes, newdata = CART_tst2, type = 'vector')
diabetes_post_response <- diabetes_post_response[,1]
diabetes_post_prob <- 1-unlist(diabetes_post_response, use.names = F)[seq(1,nrow(CART_tst2),1)]
diabetes_post_prob
diabetes_post_rocr <- prediction(diabetes_post_prob, CART_tst2$diabetesYN)
diabetes_post_perf <- performance(diabetes_post_rocr, "tpr", "fpr")
plot(diabetes_post_perf, col = 5, lwd = 3)
Perf_Table2[2,7] <- unlist(performance(diabetes_post_rocr, "auc")@y.values)
Perf_Table2
#question 3-2
#Pre_Pruning
set.seed(12345)
trn_pre2 <- diabetes_data[sample(nrow(diabetes_data),307),]
val_pre2 <- diabetes_data[sample(nrow(diabetes_data),154),]
tst_pre2 <- diabetes_data[sample(nrow(diabetes_data),307),]
CART_pre_trn2 <- data.frame(trn_pre2[,input_idx2], diabetesYN = trn_pre2[,target_idx2])
CART_pre_val2 <- data.frame(val_pre2[,input_idx2], diabetesYN = val_pre2[,target_idx2])
CART_pre_tst2 <- data.frame(tst_pre2[,input_idx2], diabetesYN = tst_pre2[,target_idx2])
min_criterion = c(0.75, 0.8, 0.85, 0.89, 0.95)
min_split = c(5,10,25,50,75,100)
max_depth = c(0,10,7,5,3)
CART_pre_search_result2 = matrix(0,length(min_criterion)*length(min_split)*length(max_depth),11)
colnames(CART_pre_search_result2) <- c("min_criterion","min_split","max_depth","TPR","Precision","TNR","ACC","BCR","F1","AUROC","N_leaves")
iter_cnt = 1
for(i in 1:length(min_criterion)){
for(j in 1:length(min_split)){
for(k in 1:length(max_depth)){
cat("CART Min Criterion:",min_criterion[i],",Minsplit:",min_split[j],",Max depth:",max_depth[k],"\n")
tmp_control = ctree_control(mincriterion = min_criterion[i],minsplit = min_split[j],maxdepth = max_depth[k])
tmp_tree <- ctree(diabetesYN ~., data = CART_pre_trn2, controls = tmp_control)
tmp_tree_val_prediction <- predict(tmp_tree, newdata = CART_pre_val2)
tmp_tree_val_response <- treeresponse(tmp_tree, newdata = CART_pre_val2)
tmp_tree_val_prob <- 1-unlist(tmp_tree_val_response, use.names = F)[seq(1,nrow(CART_pre_val2)*2,2)]
tmp_tree_val_rocr <- prediction(tmp_tree_val_prob,CART_pre_val2$diabetesYN)
tmp_tree_val_cm <- table(CART_pre_val2$diabetesYN, tmp_tree_val_prediction)
tmp_tree_val_cm
CART_pre_search_result[iter_cnt,1] = min_criterion[i]
CART_pre_search_result[iter_cnt,2] = min_split[j]
CART_pre_search_result[iter_cnt,3] = max_depth[k]
CART_pre_search_result[iter_cnt,4:9] = perf_eval(tmp_tree_val_cm)
CART_pre_search_result[iter_cnt,10] = unlist(performance(tmp_tree_val_rocr,"auc")@y.values)
CART_pre_search_result[iter_cnt,11] = length(nodes(tmp_tree,unique(where(tmp_tree))))
iter_cnt = iter_cnt + 1
}
}
}
#finding the best set of parameters
CART_pre_search_result_diabetes <- CART_pre_search_result[order(CART_pre_search_result[,10],decreasing = T),]
CART_pre_search_result_diabetes
best_criterion <- CART_pre_search_result_diabetes[1,1]
best_split <- CART_pre_search_result_diabetes[1,2]
best_depth <- CART_pre_search_result_diabetes[1,3]
#construct the best tree
tree_control = ctree_control(mincriterion = best_criterion, minsplit = best_split, maxdepth = best_depth)
# Use the training and validation dataset to train the best tree
CART2_trn2 <- rbind(CART_pre_trn2,CART_pre_val2)
CART2_pre2 <- ctree(diabetesYN ~., data = CART2_trn2, controls = tree_control)
CART_pre_prediction2 <- predict(CART2_pre2, newdata = CART_pre_tst2)
CART_pre_response2 <- treeresponse(CART2_pre2, newdata = CART_pre_tst2)
# Performance of the best tree
CART_pre_cm_diabetes <- table(CART_pre_tst2$diabetesYN, CART_pre_prediction2)
CART_pre_cm_diabetes
Perf_Table2[3,1:6] <- perf_eval(CART_pre_cm_diabetes)
Perf_Table2
# Plot the ROC
CART_pre_prob2 <- 1-unlist(CART_pre_response2, use.names=F)[seq(1,nrow(CART_tst2)*2,2)]
CART_pre_rocr2 <- prediction(CART_pre_prob2, CART_tst2$diabetesYN)
CART_pre_perf2 <- performance(CART_pre_rocr2, "tpr","fpr")
plot(CART_pre_perf2, col=5, lwd = 3)
Perf_Table2[3,7] <- unlist(performance(CART_pre_rocr2, "auc")@y.values)
Perf_Table2
# Plot the best tree
plot(CART2_pre2)
#question 6
# Initialize the performance matrix for lp
perf_mat <- matrix(0, 4, 6)
colnames(perf_mat) <- c("TPR (Recall)", "Precision", "TNR", "ACC", "BCR", "F1")
rownames(perf_mat) <- c("LogReg-Heart", "CART-Heart", "LogReg-diabetes", "CART-diabetes")
perf_mat
#input LogReg data
perf_mat[1,] <- perf_eval(cm_full)
perf_mat
#input best CART data
perf_mat[2,] <- perf_eval(CART_cm)
perf_mat
For dataset1 = Heart.csv
# Performance Evaluation Function -----------------------------------------
perf_eval <- function(cm){
# True positive rate: TPR (Recall)
TPR <- cm[2,2]/sum(cm[2,])
# Precision
PRE <- cm[2,2]/sum(cm[,2])
# True negative rate: TNR
TNR <- cm[1,1]/sum(cm[1,])
# Simple Accuracy
ACC <- (cm[1,1]+cm[2,2])/sum(cm)
# Balanced Correction Rate
BCR <- sqrt(TPR*TNR)
# F1-Measure
F1 <- 2*TPR*PRE/(TPR+PRE)
return(c(TPR, PRE, TNR, ACC, BCR, F1))
}
# Performance table
Perf_Table <- matrix(0,3,7)
rownames(Perf_Table) <- c("No-Pruning", "Post-Pruning", "Pre-Pruning")
colnames(Perf_Table) <- c("TPR", "Precision", "TNR", "Accuracy", "BCR", "F1-Measure", "AUROC")
Perf_Table
#calling & preprocessing for dataset 1
Heart <- read.csv("heart.csv")
int_idx <- c(1,4,5,8,10,11)
bin_idx <- c(2,3,6,7,9,12,13)
tar_idx <- 14
factor <- lapply(Heart[,bin_idx],factor)
input <- Heart[,int_idx]
Heart_input <- cbind(factor,input)
Heart_target <- as.factor(Heart[,tar_idx])
Heart_data <- data.frame(Heart_input,Heart_target)
#Split the dataset
set.seed(12345)
trn_idx <- Heart_data[sample(nrow(Heart_data),200),]
tst_idx <- Heart_data[sample(nrow(Heart_data),103),]
#Classification and Regression Tree(CART)
CART_trn <- data.frame(trn_idx[,input_idx],HeartYN = trn_idx[,tar_idx])
CART_tst <- data.frame(tst_idx[,input_idx],HeartYN = tst_idx[,tar_idx])
#Training the tree
CART <- tree(HeartYN ~ ., CART_trn)
summary(CART)
plot(CART)
text(CART, pretty = 1)
#Prediction
CART_prey <- predict(CART, CART_tst, type = "class")
CART_cm <- table(CART_tst$HeartYN, CART_prey)
CART_cm
#Performance Evaluation
Perf_Table[1,1:6] <- perf_eval(CART_cm)
CART_response <- predict(CART, newdata = CART_tst, type = 'vector')
CART_response <- CART_response[,1]
CART_prob <- 1-unlist(CART_response, use.names = F)[seq(1,nrow(CART_tst),1)]
CART_prob
CART_rocr <- prediction(CART_prob, CART_tst$HeartYN)
CART_perf <- performance(CART_rocr, "tpr", "fpr")
plot(CART_perf, col = 5, lwd = 3)
Perf_Table[1,7] <- unlist(performance(CART_rocr, "auc")@y.values)
Perf_Table
#question 3-1
#Post_Pruning
set.seed(12345)
CART_post_cv <- cv.tree(CART, FUN = prune.misclass)
plot(CART_post_cv$size, CART_post_cv$dev, type = "b")
CART_post_cv
#Set best size which has minimum dev.
CART_post_pruned <- prune.misclass(CART, best = 5)
summary(CART_post_pruned)
plot(CART_post_pruned)
text(CART_post_pruned, pretty = 1)
CART_post_prey <- predict(CART_post_pruned,CART_tst, type = "class")
CART_post_cm <- table(CART_tst$HeartYN, CART_post_prey)
CART_post_cm
Perf_Table[2,1:6] <- perf_eval(CART_post_cm)
Perf_Table
heart_post_response <- predict(CART_post_pruned, newdata = CART_tst, type = 'vector')
heart_post_response <- heart_post_response[,1]
heart_post_prob <- 1-unlist(heart_post_response, use.names = F)[seq(1,nrow(CART_tst),1)]
heart_post_prob
heart_post_rocr <- prediction(heart_post_prob, CART_tst$HeartYN)
heart_post_perf <- performance(heart_post_rocr, "tpr", "fpr")
plot(heart_post_perf, col = 5, lwd = 3)
Perf_Table[2,7] <- unlist(performance(heart_post_rocr, "auc")@y.values)
Perf_Table
#question 3-2
#Pre_Pruning
set.seed(12345)
trn_pre <- Heart_data[sample(nrow(Heart_data),120),]
val_pre <- Heart_data[sample(nrow(Heart_data),63),]
tst_pre <- Heart_data[sample(nrow(Heart_data),120),]
CART_pre_trn <- data.frame(trn_pre[,input_idx], HeartYN = trn_pre[,tar_idx])
CART_pre_val <- data.frame(val_pre[,input_idx], HeartYN = val_pre[,tar_idx])
CART_pre_tst <- data.frame(tst_pre[,input_idx], HeartYN = tst_pre[,tar_idx])
min_criterion = c(0.75, 0.8, 0.85, 0.89, 0.95)
min_split = c(10,25,50,75,100)
max_depth = c(0,10,7,5,3)
CART_pre_search_result = matrix(0,length(min_criterion)*length(min_split)*length(max_depth),11)
colnames(CART_pre_search_result) <- c("min_criterion","min_split","max_depth","TPR","Precision","TNR","ACC","BCR","F1","AUROC","N_leaves")
iter_cnt = 1
for(i in 1:length(min_criterion)){
for(j in 1:length(min_split)){
for(k in 1:length(max_depth)){
cat("CART Min Criterion:",min_criterion[i],",Minsplit:",min_split[j],",Max depth:",max_depth[k],"\n")
tmp_control = ctree_control(mincriterion = min_criterion[i],minsplit = min_split[j],maxdepth = max_depth[k])
tmp_tree <- ctree(HeartYN ~., data = CART_pre_trn, controls = tmp_control)
tmp_tree_val_prediction <- predict(tmp_tree, newdata = CART_pre_val)
tmp_tree_val_response <- treeresponse(tmp_tree, newdata = CART_pre_val)
tmp_tree_val_prob <- 1-unlist(tmp_tree_val_response, use.names = F)[seq(1,nrow(CART_pre_val)*2,2)]
tmp_tree_val_rocr <- prediction(tmp_tree_val_prob,CART_pre_val$HeartYN)
tmp_tree_val_cm <- table(CART_pre_val$HeartYN, tmp_tree_val_prediction)
tmp_tree_val_cm
CART_pre_search_result[iter_cnt,1] = min_criterion[i]
CART_pre_search_result[iter_cnt,2] = min_split[j]
CART_pre_search_result[iter_cnt,3] = max_depth[k]
CART_pre_search_result[iter_cnt,4:9] = perf_eval(tmp_tree_val_cm)
CART_pre_search_result[iter_cnt,10] = unlist(performance(tmp_tree_val_rocr,"auc")@y.values)
CART_pre_search_result[iter_cnt,11] = length(nodes(tmp_tree,unique(where(tmp_tree))))
iter_cnt = iter_cnt + 1
}
}
}
#finding the best tree
CART_pre_search_result <- CART_pre_search_result[order(CART_pre_search_result[,10],decreasing = T),]
CART_pre_search_result
best_criterion <- CART_pre_search_result[1,1]
best_split <- CART_pre_search_result[1,2]
best_depth <- CART_pre_search_result[1,3]
#construct the best tree
tree_control = ctree_control(mincriterion = best_criterion, minsplit = best_split, maxdepth = best_depth)
# Use the training and validation dataset to train the best tree
CART2_trn <- rbind(CART_pre_trn,CART_pre_val)
CART2_pre <- ctree(HeartYN ~., data = CART2_trn, controls = tree_control)
CART_pre_prediction <- predict(CART2_pre, newdata = CART_pre_tst)
CART_pre_response <- treeresponse(CART2_pre, newdata = CART_pre_tst)
# Performance of the best tree
CART_pre_cm <- table(CART_pre_tst$HeartYN, CART_pre_prediction)
CART_pre_cm
Perf_Table[3,1:6] <- perf_eval(CART_pre_cm)
Perf_Table
# Plot the ROC
CART_pre_prob <- 1-unlist(CART_pre_response, use.names=F)[seq(1,nrow(CART_tst)*2,2)]
CART_pre_rocr <- prediction(CART_pre_prob, CART_tst$HeartYN)
CART_pre_perf <- performance(CART_pre_rocr, "tpr","fpr")
plot(CART_pre_perf, col=5, lwd = 3)
Perf_Table[3,7] = unlist(performance(CART_pre_rocr, "auc")@y.values)
Perf_Table
# Plot the best tree
plot(CART2_pre)
plot(CART2_pre, type = "simple")
#question 6
# Initialize the performance matrix for lp, tree
perf_mat <- matrix(0, 4, 6)
colnames(perf_mat) <- c("TPR (Recall)", "Precision", "TNR", "ACC", "BCR", "F1")
rownames(perf_mat) <- c("LogReg-Heart", "CART-Heart", "LogReg-diabetes", "CART-diabetes")
perf_mat
# Split the data into the training/validation sets
Heart2 <- read.csv("heart.csv")
int_idx2 <- c(1,4,5,8,10,11)
bin_idx2 <- c(2,3,6,7,9,12,13)
tar_idx2 <- 14
for(i in int_idx2){
Heart2[,i] <- scale(Heart2[,i], center = TRUE, scale = TRUE)
}
factor <- lapply(Heart2[,bin_idx2],factor)
input2 <- Heart2[,int_idx2]
Heart_input2 <- cbind(factor,input2)
Heart_target2 <- as.factor(Heart2[,tar_idx2])
Heart_data2 <- data.frame(Heart_input2,Heart_target2)
#Split the dataset
set.seed(12345)
trn_idx2 <- sample(1:nrow(Heart_data2), round(0.7*nrow(Heart_data2)))
Heart_trn2 <- Heart_data2[trn_idx2,]
Heart_tst2 <- Heart_data2[-trn_idx2,]
#logistic regression - Heart
full_lr1 <- glm(Heart_target2 ~ ., family=binomial, data = Heart_trn2)
summary(full_lr1)
lr_response1 <- predict(full_lr1, type = "response", newdata = Heart_tst2)
lr_target1 <- Heart_tst2$Heart_target2
lr_predicted1 <- rep(0, length(lr_target1))
lr_predicted1[which(lr_response1 >= 0.5)] <- 1
cm_full <- table(lr_target1, lr_predicted1)
cm_full
#input LogReg data
perf_mat[1,] <- perf_eval(cm_full)
perf_mat
#input best CART data
perf_mat[2,] <- perf_eval(CART_cm)
perf_mat
#==============================================================================#
#==============================================================================#
#==============================================================================#
#for dataset 2: diabetes.csv
# Performance table
Perf_Table2 <- matrix(0,3,7)
rownames(Perf_Table2) <- c("No-Pruning", "Post-Pruning", "Pre-Pruning")
colnames(Perf_Table2) <- c("TPR", "Precision", "TNR", "Accuracy", "BCR", "F1-Measure", "AUROC")
Perf_Table2
#calling & preprocessing for dataset 2
diabetes <- read.csv("diabetes.csv")
input_idx2 <- c(1,2,3,4,5,6,7,8)
target_idx2 <- 9
diabetes_input <- diabetes[,input_idx2]
diabetes_target <- as.factor(diabetes[,target_idx2])
diabetes_data <- data.frame(diabetes_input, diabetes_target)
describe(diabetes_data)
#Split the dataset
set.seed(12345)
trn_idx3 <- diabetes_data[sample(nrow(diabetes_data),461),]
tst_idx3 <- diabetes_data[sample(nrow(diabetes_data),307),]
#Classification and Regression Tree(CART)
CART_trn2 <- data.frame(trn_idx3[,input_idx2],diabetesYN = trn_idx3[,target_idx2])
CART_tst2 <- data.frame(tst_idx3[,input_idx2],diabetesYN = tst_idx3[,target_idx2])
#Training the tree
CART_diabetes <- tree(diabetesYN ~ ., CART_trn2)
summary(CART_diabetes)
plot(CART_diabetes)
text(CART_diabetes, pretty = 1)
#Prediction
CART_prey2 <- predict(CART_diabetes, CART_tst2, type = "class")
CART_cm_diabetes <- table(CART_tst2$diabetesYN, CART_prey2)
CART_cm_diabetes
#Performance Evaluation
Perf_Table2[1,1:6] <- perf_eval(CART_cm_diabetes)
Perf_Table2
diabetes_CART_response <- predict(CART_diabetes, newdata = CART_tst2, type = 'vector')
diabetes_CART_response <- diabetes_CART_response[,1]
diabetes_CART_prob <- 1-unlist(diabetes_CART_response, use.names = F)[seq(1,nrow(CART_tst2),1)]
diabetes_CART_prob
diabetes_CART_rocr <- prediction(diabetes_CART_prob, CART_tst2$diabetesYN)
diabetes_CART_perf <- performance(diabetes_CART_rocr, "tpr", "fpr")
plot(diabetes_CART_perf, col = 5, lwd = 3)
Perf_Table2[1,7] <- unlist(performance(diabetes_CART_rocr, "auc")@y.values)
Perf_Table2
#question 3-1
#Post_Pruning
set.seed(12345)
CART_post_diabetes <- cv.tree(CART_diabetes, FUN = prune.misclass)
plot(CART_post_diabetes$size, CART_post_diabetes$dev, type = "b")
CART_post_diabetes
#Set best size which has minimum dev.
CART_post_pruned_diabetes <- prune.misclass(CART_diabetes, best = 4)
summary(CART_post_pruned_diabetes)
plot(CART_post_pruned_diabetes)
text(CART_post_pruned_diabetes, pretty = 1)
CART_post_prey_diabetes <- predict(CART_post_pruned_diabetes,CART_tst2, type = "class")
CART_post_cm_diabetes <- table(CART_tst2$diabetesYN, CART_post_prey_diabetes)
CART_post_cm_diabetes
Perf_Table2[2,1:6] <- perf_eval(CART_post_cm_diabetes)
Perf_Table2
diabetes_post_response <- predict(CART_post_pruned_diabetes, newdata = CART_tst2, type = 'vector')
diabetes_post_response <- diabetes_post_response[,1]
diabetes_post_prob <- 1-unlist(diabetes_post_response, use.names = F)[seq(1,nrow(CART_tst2),1)]
diabetes_post_prob
diabetes_post_rocr <- prediction(diabetes_post_prob, CART_tst2$diabetesYN)
diabetes_post_perf <- performance(diabetes_post_rocr, "tpr", "fpr")
plot(diabetes_post_perf, col = 5, lwd = 3)
Perf_Table2[2,7] <- unlist(performance(diabetes_post_rocr, "auc")@y.values)
Perf_Table2
#question 3-2
#Pre_Pruning
set.seed(12345)
trn_pre2 <- diabetes_data[sample(nrow(diabetes_data),307),]
val_pre2 <- diabetes_data[sample(nrow(diabetes_data),154),]
tst_pre2 <- diabetes_data[sample(nrow(diabetes_data),307),]
CART_pre_trn2 <- data.frame(trn_pre2[,input_idx2], diabetesYN = trn_pre2[,target_idx2])
CART_pre_val2 <- data.frame(val_pre2[,input_idx2], diabetesYN = val_pre2[,target_idx2])
CART_pre_tst2 <- data.frame(tst_pre2[,input_idx2], diabetesYN = tst_pre2[,target_idx2])
min_criterion = c(0.75, 0.8, 0.85, 0.89, 0.95)
min_split = c(5,10,25,50,75,100)
max_depth = c(0,10,7,5,3)
CART_pre_search_result2 = matrix(0,length(min_criterion)*length(min_split)*length(max_depth),11)
colnames(CART_pre_search_result2) <- c("min_criterion","min_split","max_depth","TPR","Precision","TNR","ACC","BCR","F1","AUROC","N_leaves")
iter_cnt = 1
for(i in 1:length(min_criterion)){
for(j in 1:length(min_split)){
for(k in 1:length(max_depth)){
cat("CART Min Criterion:",min_criterion[i],",Minsplit:",min_split[j],",Max depth:",max_depth[k],"\n")
tmp_control = ctree_control(mincriterion = min_criterion[i],minsplit = min_split[j],maxdepth = max_depth[k])
tmp_tree <- ctree(diabetesYN ~., data = CART_pre_trn2, controls = tmp_control)
tmp_tree_val_prediction <- predict(tmp_tree, newdata = CART_pre_val2)
tmp_tree_val_response <- treeresponse(tmp_tree, newdata = CART_pre_val2)
tmp_tree_val_prob <- 1-unlist(tmp_tree_val_response, use.names = F)[seq(1,nrow(CART_pre_val2)*2,2)]
tmp_tree_val_rocr <- prediction(tmp_tree_val_prob,CART_pre_val2$diabetesYN)
tmp_tree_val_cm <- table(CART_pre_val2$diabetesYN, tmp_tree_val_prediction)
tmp_tree_val_cm
CART_pre_search_result[iter_cnt,1] = min_criterion[i]
CART_pre_search_result[iter_cnt,2] = min_split[j]
CART_pre_search_result[iter_cnt,3] = max_depth[k]
CART_pre_search_result[iter_cnt,4:9] = perf_eval(tmp_tree_val_cm)
CART_pre_search_result[iter_cnt,10] = unlist(performance(tmp_tree_val_rocr,"auc")@y.values)
CART_pre_search_result[iter_cnt,11] = length(nodes(tmp_tree,unique(where(tmp_tree))))
iter_cnt = iter_cnt + 1
}
}
}
#finding the best set of parameters
CART_pre_search_result_diabetes <- CART_pre_search_result[order(CART_pre_search_result[,10],decreasing = T),]
CART_pre_search_result_diabetes
best_criterion <- CART_pre_search_result_diabetes[1,1]
best_split <- CART_pre_search_result_diabetes[1,2]
best_depth <- CART_pre_search_result_diabetes[1,3]
#construct the best tree
tree_control = ctree_control(mincriterion = best_criterion, minsplit = best_split, maxdepth = best_depth)
# Use the training and validation dataset to train the best tree
CART2_trn2 <- rbind(CART_pre_trn2,CART_pre_val2)
CART2_pre2 <- ctree(diabetesYN ~., data = CART2_trn2, controls = tree_control)
CART_pre_prediction2 <- predict(CART2_pre2, newdata = CART_pre_tst2)
CART_pre_response2 <- treeresponse(CART2_pre2, newdata = CART_pre_tst2)
# Performance of the best tree
CART_pre_cm_diabetes <- table(CART_pre_tst2$diabetesYN, CART_pre_prediction2)
CART_pre_cm_diabetes
Perf_Table2[3,1:6] <- perf_eval(CART_pre_cm_diabetes)
Perf_Table2
# Plot the ROC
CART_pre_prob2 <- 1-unlist(CART_pre_response2, use.names=F)[seq(1,nrow(CART_tst2)*2,2)]
CART_pre_rocr2 <- prediction(CART_pre_prob2, CART_tst2$diabetesYN)
CART_pre_perf2 <- performance(CART_pre_rocr2, "tpr","fpr")
plot(CART_pre_perf2, col=5, lwd = 3)
Perf_Table2[3,7] <- unlist(performance(CART_pre_rocr2, "auc")@y.values)
Perf_Table2
# Plot the best tree
plot(CART2_pre2)
plot(CART2_pre2, type = "simple")
#question 6
# Split the data into the training/validation sets
diabetes2 <- read.csv("diabetes.csv")
input_idx_last <- c(1,2,3,4,5,6,7,8)
target_idx_last <- 9
diabetes_input_last <- diabetes2[,input_idx_last]
diabetes_target_last <- as.factor(diabetes2[,target_idx_last])
diabetes_data_last <- data.frame(diabetes_input_last, diabetes_target_last)
# Conduct the normalization
diabetes_input_last <- diabetes2[,input_idx_last]
diabetes_input_last <- scale(diabetes_input_last, center = TRUE, scale = TRUE)
diabetes_target_last <- diabetes2[,target_idx_last]
diabetes_data_last <- data.frame(diabetes_input_last, diabetes_target_last)
# Split the data into the training/validation sets
set.seed(12345)
trn_idx_last <- sample(1:nrow(diabetes_data_last), round(0.7*nrow(diabetes_data_last)))
diabetes_trn_last <- diabetes_data_last[trn_idx_last,]
diabetes_tst_last <- diabetes_data_last[-trn_idx_last,]
# Train the Logistic Regression Model with all variables
full_lr2 <- glm(diabetes_target_last ~ ., family=binomial, data = diabetes_trn_last)
summary(full_lr2)
lr_response2 <- predict(full_lr2, type = "response", newdata = diabetes_tst_last)
lr_target2 <- diabetes_tst_last$diabetes_target_last
lr_predicted2 <- rep(0, length(lr_target2))
lr_predicted2[which(lr_response2 >= 0.5)] <- 1
cm_full_last <- table(lr_target2, lr_predicted2)
cm_full_last
#input LogReg data
perf_mat[3,] <- perf_eval(cm_full_last)
perf_mat
#input best CART data
perf_mat[4,] <- perf_eval(CART_cm_diabetes)
perf_mat
#summary of each model
summary(CART)
summary(CART_diabetes)
summary(CART_diabetes)
summary(full_lr2)
#summary of each model
summary(CART)
#summary of each model
plot(CART, type = 'simple')
plot(CART)
text(CART, pretty = 1)
#summary of each model
plot(CART, type = 'simple')
#summary of each model
plot(CART)
text(CART, pretty = 1)
plot(CART_diabetes)
plot(CART_diabetes)
text(CART_diabets, pretty = 1)
summary(full_lr2)
text(CART_diabets, pretty = 1)
text(CART_diabetes, pretty = 1)
#summary of each model
plot(CART)
text(CART, pretty = 1)
summary(full_lr1)
plot(CART_diabetes)
text(CART_diabetes, pretty = 1)
summary(full_lr2)
summary(full_lr1)
#summary of each model
plot(CART)
text(CART, pretty = 1)
summary(full_lr2)
summary(full_lr2)
text(CART_diabetes, pretty = 1)
#summary of each model
plot(CART_diabetes)
text(CART_diabetes, pretty = 1)
